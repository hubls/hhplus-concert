# ⚡부하 테스트 보고서

## 부하 테스트 대상 API 선정
> 부하 테스트를 위해 4개의 API를 선정했습니다. 실제 서비스 운영 시 트래픽이 집중될 가능성이 높은 작업을 기준으로 선정했습니다.

1. `POST /api/v1/queue/tokens`: 대기열 토큰 생성 및 진입
- 콘서트 예약하기 위해서 토큰을 발급받아야 하기에 많은 요청이 예상되는 API입니다.
평소에 많은 부하가 일어나지 않지만, 특정 시점에서 순간적으로 많은 부하가 생길 수 있습니다.
따라서 최대 처리 능력을 보는 것이 중요할 것 같습니다.

2. `GET /api/v1/queue/status`: 대기열 토큰 정보 조회
- 대기열 토큰 생성 요청 후, 유저들은 자신의 토큰 상태(언제 접속이 가능한지)를 확인하기 위해 지속적으로 요청하는 API입니다.
대기열 토큰 생성 API와 마찬가지로, 특정 시점에 순간적으로 많은 부하가 생길 수 있습니다.
추가로, 지속적으로 유저가 확인하므로 더 많은 부하가 예상됩니다.

3. `GET /api/v1/concert/{concertId}/schedules`: 예약 가능 일정 조회
- 예약 가능한 일정을 조회하기 위해 사용되는 API입니다. 
한 번 요청 후, 지속적으로 요청하게 되는 API는 아닐 것으로 예상합니다.
하지만 한 번 요청했을 때 데이터가 잘못 전달 되면, 올바른 데이터를 수신받기 위해 지속적으로 요청하여 부하가 생길 수 있습니다.

4. `GET /api/v1/concert/{concertId}/schedules/{scheduleId}/seats`
- 대기열에 진입에 성공한 유저들이 예약 가능한 일정 조회를 마치고, 좌석을 조회하기 위해 사용하는 API입니다.
좌석이 남아있는지, 지속적으로 확인할 수 있으므로 많은 부하가 생길 수 있습니다.

---

## 테스트 환경 설정
### 장비 및 시스템 환경
- 운영 체제: Window11
- 모델명: 16ZD90P-GX76K
- CPU: i7-1165G7 2.80GHz
- RAM: 16GB

### 테스트 및 모니터링 툴
- K6: v0.57.0

### 툴 선정 기준
- 자바스크립트에 익숙하기때문에, 추가 학습 없이 빠르게 부하 테스트를 작성할 수 있다는 점에서 효율적이었습니다.
- k6는 CLI 기반으로 설정과 실행이 매우 간단합니다. 또한, JSON 또는 JavaScript 파일을 사용해 테스트 시나리오를 정의할 수 있어 빠르게 설정을 마칠 수 있습니다.

---

## 테스트 시나리오 및 수행 결과 분석
### 1. `POST /api/v1/queue/tokens`: 대기열 토큰 생성 및 진입
> 이 테스트는 많은 유저가 동시에 대기열에 진입할 때(API 요청 보낼 때) 시스템의 처리 능력을 평가합니다.
> 목표는 대기열 생성 과정에서의 최대 처리 능력을 확인하고, 고부하 상태에서 안정적으로 동작하는지 평가하겠습니다.

#### 테스트 시나리오
- 유저는 미리 데이터베이스에 200명 추가해두겠습니다.
- 200명의 유저가 동시에 대기열에 진입하려고 시도합니다.
- 각 유저는 토큰 발급 요청을 보내며, 서버는 이를 처리하여 대기열 토큰을 발급합니다.
- 발급된 토큰이 정상적으로 응답되었는지 확인합니다.

#### 부하 조건
- 유저 수: 초당 50명에서 100명까지 유저 증가
- 지속 시간: 1분, 최대 peak 20초간 일정한 부하를 유지
- 선정 이유: 대기열 토큰 생성은 트래픽이 몰릴 때 시스템에서 가장 큰 부하를 발생시킬 수 있는 API입니다.
트래픽이 증가하는 상황에서 서버의 처리 능력을 평가하기 위해 초당 유저 수를 점진적으로 증가시켜 부하를 가합니다.
이 설정은 서버가 트래픽 급증 시 안정적으로 작동하는지 확인하는 데 적합합니다.
- 예상 트래픽: 목표 TPS는 200이상으로 설정하며, 초당 최대 200개의 대기열 토큰 생성 요청이 발생할 수 있는 상황을 가정하여 서버의 응답 성능을 평가합니다.


#### K6 테스트 코드
```javascript
import http from 'k6/http';
import { check, sleep } from 'k6';

export let options = {
  stages: [
    { duration: '20s', target: 50 },
    { duration: '20s', target: 100 },
    { duration: '20s', target: 50}
  ],
  thresholds: {
    http_req_duration: ['p(95)<500'], // 95%의 요청이 500ms 미만이어야 함
    http_req_failed: ['rate<0.01'],  // 실패율은 1% 미만
  }
};

export default function () {
  let userId = Math.floor(Math.random() * 200) + 1;

  let url = 'http://localhost:8080/api/v1/queue/tokens';
  let payload = JSON.stringify({
    userId: userId
  });

  let params = {
    headers: {
      'Content-Type': 'application/json'
    }
  };

  // HTTP POST 요청
  let res = http.post(url, payload, params);

  // 응답 검증
  check(res, {
    'status is 201': (r) => r.status ===201,
    'response time < 500ms': (r) => r.timings.duration < 500
  });

  // 요청 간격
  sleep(0.5)
}
```

#### K6 테스트 결과 분석
```text
execution: local
script: api-queue-token-test.js
output: -

scenarios: (100.00%) 1 scenario, 100 max VUs, 1m30s max duration (incl. graceful stop):
      * default: Up to 100 looping VUs for 1m0s over 3 stages (gracefulRampDown: 30s, gracefulStop: 30s)


✓ status is 201
✓ response time < 500ms

checks.........................: 100.00% 13396 out of 13396
data_received..................: 1.4 MB  23 kB/s
data_sent......................: 1.1 MB  18 kB/s
http_req_blocked...............: avg=12.84µs  min=0s       med=0s       max=4.69ms   p(90)=0s       p(95)=0s
http_req_connecting............: avg=9.19µs   min=0s       med=0s       max=1.33ms   p(90)=0s       p(95)=0s
✓ http_req_duration..............: avg=26.28ms  min=14.26ms  med=25.83ms  max=42.85ms  p(90)=31.57ms  p(95)=33.64ms
{ expected_response:true }...: avg=26.28ms  min=14.26ms  med=25.83ms  max=42.85ms  p(90)=31.57ms  p(95)=33.64ms
✓ http_req_failed................: 0.00%   0 out of 6698
http_req_receiving.............: avg=295.85µs min=0s       med=190.1µs  max=1.58ms   p(90)=821.24µs p(95)=940.04µs
http_req_sending...............: avg=10.38µs  min=0s       med=0s       max=689.7µs  p(90)=0s       p(95)=0s
http_req_tls_handshaking.......: avg=0s       min=0s       med=0s       max=0s       p(90)=0s       p(95)=0s
http_req_waiting...............: avg=25.98ms  min=14.26ms  med=25.51ms  max=42.09ms  p(90)=31.26ms  p(95)=33.34ms
http_reqs......................: 6698    110.688809/s
iteration_duration.............: avg=526.81ms min=515.59ms med=526.35ms max=544.28ms p(90)=532.09ms p(95)=534.13ms
iterations.....................: 6698    110.688809/s
vus............................: 51      min=3              max=99
vus_max........................: 100     min=100            max=100
```

#### 1) 전체적인 실행 정보
- 총 실행 시간: 1분 30초 (90초)
- 최대 동시 가상 유저(VU, Virtual Users) 수: 100명
- 총 요청 횟수: 6,698회
- 초당 평균 요청 수 (TPS, Throughput Per Second): 110.69회

> 테스트 목표에 따라 최대 100명의 동시 사용자(VU)로 1분간 요청을 보냈으며, 초당 약 110건의 요청을 처리했습니다.

#### 2) 주요 성능 지표 (서버 응답 시간 및 요청 성공률)
| 항목                         | 설명                                    | 결과                |
|------------------------------|-----------------------------------------|---------------------|
| 성공한 요청 비율             | HTTP 201 응답을 받은 비율               | 100% (6,698/6,698)  |
| 평균 응답 시간               | 요청 후 응답까지 걸린 평균 시간         | 26.28ms             |
| 최소 응답 시간               | 가장 빠른 요청의 응답 시간             | 14.26ms             |
| 최대 응답 시간               | 가장 오래 걸린 요청의 응답 시간        | 42.85ms             |
| 응답 시간 (90% 이하 요청)     | 90%의 요청이 이 시간보다 빠름          | 31.57ms             |
| 응답 시간 (95% 이하 요청)     | 95%의 요청이 이 시간보다 빠름          | 33.64ms             |

- 서버 응답 시간이 평균 26.28ms로 매우 빠르며, 90%의 요청이 31.57ms 이하로 처리되었습니다.
- 최대 응답 시간도 42.85ms로, 성능 목표(500ms 이하)를 훨씬 초과하여 안정적인 응답 속도를 유지했습니다.
- 요청 실패율은 0%로, 모든 요청이 정상적으로 처리되었습니다.

#### 3) 부가적인 요청 상세 정보
| 항목                         | 설명                                        | 결과         |
|------------------------------|---------------------------------------------|-------------|
| 전송된 총 데이터 크기         | 서버로 보낸 총 데이터 양                    | 1.1MB       |
| 받은 총 데이터 크기           | 서버에서 받은 총 데이터 양                  | 1.4MB       |
| 요청 대기 시간 (Waiting Time) | 서버가 실제 요청을 처리하는 데 걸린 시간   | 평균 25.98ms |
| 요청 블로킹 시간 (Blocked Time) | 요청이 전송되기 전 대기한 시간             | 평균 12.84µs |
| 연결 시간 (Connecting Time)   | 서버와 연결하는 데 걸린 시간                | 평균 9.19µs  |

- 요청-응답 과정이 매우 원활하게 진행되었으며, 네트워크 지연이 거의 발생하지 않았습니다.

#### 📌 종합 결론
- 초당 110건의 요청을 처리하면서도 평균 응답 시간 26ms를 유지, 성능 목표를 충분히 만족했습니다.
- 95%의 요청이 34ms 이내에 처리되었고, 실패율 0%로 안정적인 상태입니다.
- 최대 응답 시간이 42.85ms로, 부하가 증가해도 빠른 성능을 유지하고 있습니다.

> 결론적으로, 현재 API는 초당 110건에서 대기열 토큰 요청을 매우 안정적으로 처리할 수 있는 성능을 갖추고 있으며, 부하 상황에서도 높은 응답 속도를 유지할 수 있습니다.




---



### 2. `GET /api/v1/queue/status`: 대기열 토큰 정보 조회
> 유저들이 지속적으로 대기열 상태를 확인하는 상황을 가정하고, 응답 성능과 안정성을 평가합니다. 특히, 다수의 유저의 확인 요청이 있을 때 서버의 성능을 분석합니다.


#### 테스트 시나리오
- 여러 유저가 자신의 대기열 상태를 지속적으로 확인하기 위해 대기열 확인 요청을 보냅니다.
- 서버는 각 유저의 대기열 상태를 반환합니다.
- 응답이 200 OK 상태인지 확인합니다.


#### 부하 조건
- 유저 수: 초당 200명씩 2번 대기열 확인 요청
- 지속 시간: 총 1분 동안 테스트를 진행하며, 20초간 최대 부하(200명)를 유지
- 선정 이유: 대기열 토큰 조회 API는 다수의 사용자가 자신의 대기 상태를 확인하기 위해 빈번하게 polling 요청을 보내는 API입니다. 
  실제 사용 환경을 반영하여 초당 200명의 사용자가 지속적으로 요청을 보낼 때 시스템의 안정성과 응답 시간을 평가할 수 있도록 설정하였습니다.
- 예상 트래픽: 목표 TPS는 400이상으로 설정하며, 이를 통해 서버가 고객 요청을 지속적으로 처리할 수 있는지 평가합니다.


#### K6 테스트 코드
```javascript
import http from 'k6/http';
import { check, sleep } from 'k6';

// 부하 조건 설정
export let options = {
  stages: [
    { duration: '20s', target: 200 }, // 20초 동안 유저 수를 200명으로 증가
    { duration: '20s', target: 200 },
    { duration: '20s', target: 200 }
  ],
  thresholds: {
    http_req_duration: ['p(95)<500'], // 95%의 요청이 500ms 미만이어야 함
    http_req_failed: ['rate<0.01'] // 실패율은 1% 미만
  }
};

export default function () {
  let token = '21d6207f-b322-3a29-b4f2-ed4d3442ad5f';

  let url = 'http://localhost:8080/api/v1/queue/status';
  let params = {
    headers: {
      'Content-Type': 'application/json',
      'Token': token,
      'User-Id': 1
    }
  };

  // HTTP GET 요청
  let res = http.get(url, params);

  // 응답 검증
  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
  });

  // 요청 간격
  sleep(0.5)
}
```

#### K6 테스트 결과 분석
```text
execution: local
script: api-queue-status-test.js
output: -

scenarios: (100.00%) 1 scenario, 200 max VUs, 1m30s max duration (incl. graceful stop):
      * default: Up to 200 looping VUs for 1m0s over 3 stages (gracefulRampDown: 30s, gracefulStop: 30s)


✓ status is 200
✓ response time < 500ms

checks.........................: 100.00% 37972 out of 37972
data_received..................: 3.9 MB  64 kB/s
data_sent......................: 3.6 MB  59 kB/s
http_req_blocked...............: avg=5.17µs   min=0s       med=0s       max=1.5ms    p(90)=0s       p(95)=0s
http_req_connecting............: avg=3.25µs   min=0s       med=0s       max=1.23ms   p(90)=0s       p(95)=0s
✓ http_req_duration..............: avg=29.03ms  min=15.56ms  med=23.82ms  max=214.04ms p(90)=37.25ms  p(95)=59.66ms
{ expected_response:true }...: avg=29.03ms  min=15.56ms  med=23.82ms  max=214.04ms p(90)=37.25ms  p(95)=59.66ms
✓ http_req_failed................: 0.00%   0 out of 18986
http_req_receiving.............: avg=247.41µs min=0s       med=0s       max=15.82ms  p(90)=753.7µs  p(95)=913.55µs
http_req_sending...............: avg=4.1µs    min=0s       med=0s       max=2ms      p(90)=0s       p(95)=0s
http_req_tls_handshaking.......: avg=0s       min=0s       med=0s       max=0s       p(90)=0s       p(95)=0s
http_req_waiting...............: avg=28.78ms  min=15.38ms  med=23.58ms  max=214.04ms p(90)=36.95ms  p(95)=59.25ms
http_reqs......................: 18986   313.705869/s
iteration_duration.............: avg=529.44ms min=516.08ms med=524.23ms max=714.39ms p(90)=537.55ms p(95)=560.07ms
iterations.....................: 18986   313.705869/s
vus............................: 200     min=10             max=200
vus_max........................: 200     min=200            max=200
```

#### 1) 전체적인 실행 정보
- 총 실행 시간: 1분 0.5초 (60.5초)
- 최대 동시 가상 유저(VU, Virtual Users) 수: 200명
- 총 요청 횟수: 18,986회
- 초당 평균 요청 수(TPS, Throughput Per Second): 313.7회

> 테스트 목표였던 초당 200명 요청을 초과하여 평균 313.7회의 요청을 처리했습니다.

#### 2) 주요 성능 지표 (서버 응답 시간 및 요청 성공률)
| 항목                     | 설명                                      | 결과                     |
|--------------------------|-----------------------------------------|------------------------|
| 성공한 요청 비율         | 전체 요청 중 HTTP 200 응답을 받은 비율  | 100% (18,986/18,986)   |
| 평균 응답 시간           | 요청을 보낸 후 응답을 받을 때까지 걸린 평균 시간 | 29.03ms                |
| 최소 응답 시간           | 가장 빠르게 응답한 요청의 응답 시간      | 15.56ms                |
| 최대 응답 시간           | 가장 오래 걸린 요청의 응답 시간          | 214.04ms               |
| 응답 시간 (90% 이하 요청) | 90%의 요청이 이 시간보다 빠름            | 37.25ms                |
| 응답 시간 (95% 이하 요청) | 95%의 요청이 이 시간보다 빠름            | 59.66ms                |
| 최대 초당 요청 수(TPS)   | 서버가 초당 처리한 최대 요청 수          | 313.7 TPS              |

- 서버 응답 시간이 평균 29ms로 매우 빠르며, 95%의 요청이 60ms 미만으로 처리되었습니다.
- 최대 응답 시간이 214ms로, 설정한 성능 목표(500ms 이하)를 충분히 만족합니다.
- 1% 이상의 실패 요청이 발생하면 안 되는데, 실패율이 0%로 안정적인 서버 상태를 유지했습니다.

#### 3) 부가적인 요청 상세 정보
| 항목                         | 설명                                        | 결과         |
|------------------------------|---------------------------------------------|-------------|
| 전송된 총 데이터 크기         | 서버로 보낸 총 데이터 양                    | 3.6MB      |
| 받은 총 데이터 크기           | 서버에서 받은 총 데이터 양                  | 3.9MB      |
| 요청 대기 시간 (Waiting Time) | 서버가 실제로 요청을 처리하는데 걸린 시간   | 평균 28.78ms |
| 요청 블로킹 시간 (Blocked Time) | 요청이 전송되기 전에 대기한 시간          | 평균 5.17µs  |
| 연결 시간 (Connecting Time)   | 서버와 연결하는데 걸린 시간                | 평균 3.25µs  |

- 서버와의 연결 지연이 거의 없으며, 요청-응답 과정이 매우 원활하게 진행되었습니다.

#### 📌 종합 결론
- 테스트 목표인 초당 200명 요청을 초과하여 초당 약 313건의 요청을 처리하면서도, 성능 목표를 충분히 만족했습니다.
- 95%의 요청이 60ms 미만으로 처리되었고, 실패율이 0%로 매우 안정적입니다.
- 최대 응답 시간이 214ms로, 부하가 증가해도 500ms 이하의 성능 목표를 유지했습니다.

> 결론적으로, 현재 서버는 초당 400개의 요청을 안정적으로 처리할 수 있는 상태입니다.



---



### 3. `GET /api/v1/concert/{concertId}/schedules`: 예약 가능 일정 조회
> 많은 유저가 동시에 예약 가능한 날짜 정보를 조회하는 상황을 가정하여, 서버의 성능과 응답 속도를 평가합니다.


#### 테스트 시나리오
- 다수의 유저가 특정 콘서트의 예약 가능 날짜를 조회합니다.
- 서버는 각 요청에 대해 200 OK 응답을 보내고, 날짜 정보를 반환합니다.
- 응답 시간과 성능을 평가합니다.

#### 부하 조건
- 유저 수: 초당 50명에서 100명까지 증가
- 지속 시간: 1분, 최대 peak 20초간 일정한 부하를 유지
- 선정 이유: 예약 가능한 날짜 조회 API는 대량의 데이터를 처리하며, 많은 유저가 동시에 요청할 때 시스템의 응답 시간이 길어질 수 있습니다. 이러한 상황을 시뮬레이션하기 위해 초당 50명에서 100명까지 유저 수를 증가시키는 부하 조건을 설정하여, 시스템의 성능을 평가합니다.
- 예상 트래픽: 목표 TPS는 100이상 으로 설정되며, 초당 최대 100개의 날짜 조회 요청이 발생할 수 있는 상황을 평가하여 시스템의 데이터 처리 성능을 분석합니다.

#### K6 테스트 코드
```javascript
import http from 'k6/http';
import { check, sleep } from 'k6';

// 부하 조건 설정
export let options = {
  stages: [
    { duration: '20s', target: 50 },  // 20초 동안 50명까지 증가
    { duration: '20s', target: 100 },  // 20초 동안 100명까지 증가
    { duration: '20s', target: 50 },  // 20초 동안 50명까지 감소
  ],
  thresholds: {
    http_req_duration: ['p(95)<500'], // 95%의 요청이 500ms 미만이어야 함
    http_req_failed: ['rate<0.01'],  // 실패율은 1% 미만
  }
};

export default function () {
  let url = 'http://localhost:8080/api/v1/concerts/1/schedules';

  // HTTP GET 요청
  let res = http.get(url);

  // 응답 검증
  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
  });

  sleep(1);
}
```

#### K6 테스트 결과 분석
```text
execution: local
  script: api-concert-schedules-test.js
  output: -

scenarios: (100.00%) 1 scenario, 100 max VUs, 1m30s max duration (incl. graceful stop):
        * default: Up to 100 looping VUs for 1m0s over 3 stages (gracefulRampDown: 30s, gracefulStop: 30s)


✓ status is 200
✓ response time < 500ms

checks.........................: 100.00% 7066 out of 7066
data_received..................: 975 kB  16 kB/s
data_sent......................: 378 kB  6.2 kB/s
http_req_blocked...............: avg=24.77µs  min=0s     med=0s      max=4.78ms   p(90)=0s       p(95)=0s
http_req_connecting............: avg=18.08µs  min=0s     med=0s      max=1.42ms   p(90)=0s       p(95)=0s
✓ http_req_duration..............: avg=4.22ms   min=1.02ms med=4.09ms  max=16.26ms  p(90)=5.86ms   p(95)=6.57ms
 { expected_response:true }...: avg=4.22ms   min=1.02ms med=4.09ms  max=16.26ms  p(90)=5.86ms   p(95)=6.57ms
✓ http_req_failed................: 0.00%   0 out of 3533
http_req_receiving.............: avg=386.07µs min=0s     med=293.2µs max=3.95ms   p(90)=949.26µs p(95)=1.02ms
http_req_sending...............: avg=10.08µs  min=0s     med=0s      max=551.79µs p(90)=0s       p(95)=0s
http_req_tls_handshaking.......: avg=0s       min=0s     med=0s      max=0s       p(90)=0s       p(95)=0s
http_req_waiting...............: avg=3.83ms   min=1.02ms med=3.67ms  max=16.26ms  p(90)=5.39ms   p(95)=6.12ms
http_reqs......................: 3533    57.954449/s
iteration_duration.............: avg=1s       min=1s     med=1s      max=1.02s    p(90)=1s       p(95)=1s
iterations.....................: 3533    57.954449/s
vus............................: 51      min=3            max=100
vus_max........................: 100     min=100          max=100
```

#### 1) 전체적인 실행 정보
- 총 실행 시간: 1분 30초 (90초)
- 최대 동시 가상 유저(VU, Virtual Users) 수: 100명
- 총 요청 횟수: 3,533회
- 초당 평균 요청 수(TPS, Throughput Per Second): 57.95회

> 목표로 설정된 VUs에 대해 초당 약 58회의 요청을 처리했습니다. 
> 예상한 것보다 상대적으로 낮은 TPS를 기록했지만, 부하 테스트에서는 안정적인 성능을 유지했습니다.
 

#### 2) 주요 성능 지표 (서버 응답 시간 및 요청 성공률)
| 항목                         | 설명                                    | 결과                    |
|------------------------------|-----------------------------------------|-------------------------|
| 성공한 요청 비율             | 전체 요청 중 HTTP 200 응답을 받은 비율 | 100% (3,533/3,533)      |
| 평균 응답 시간               | 요청을 보낸 후 응답을 받을 때까지 걸린 평균 시간 | 4.22ms                  |
| 최소 응답 시간               | 가장 빠르게 응답한 요청의 응답 시간    | 1.02ms                  |
| 최대 응답 시간               | 가장 오래 걸린 요청의 응답 시간       | 16.26ms                 |
| 응답 시간 (90% 이하 요청)     | 90%의 요청이 이 시간보다 빠름          | 5.86ms                  |
| 응답 시간 (95% 이하 요청)     | 95%의 요청이 이 시간보다 빠름          | 6.57ms                  |
| 최대 초당 요청 수(TPS)       | 서버가 초당 처리한 최대 요청 수        | 57.95 TPS               |


- 서버 응답 시간이 매우 빠름: 평균 4.22ms로, 95%의 요청이 6.57ms 이내로 처리되었습니다. 이는 매우 빠른 응답 시간으로 성능 목표를 충분히 충족합니다.
- 실패율이 0%: 모든 요청에서 HTTP 200 응답을 받아, 서버가 안정적으로 요청을 처리했습니다.
- 최대 응답 시간은 16.26ms로, 설정한 성능 목표(500ms 이하)를 만족했습니다.

#### 3) 부가적인 요청 상세 정보
| 항목                         | 설명                                        | 결과          |
|------------------------------|---------------------------------------------|--------------|
| 전송된 총 데이터 크기         | 서버로 보낸 총 데이터 양                    | 378 kB       |
| 받은 총 데이터 크기           | 서버에서 받은 총 데이터 양                  | 975 kB       |
| 요청 대기 시간 (Waiting Time) | 서버가 실제로 요청을 처리하는 데 걸린 시간   | 평균 3.83ms  |
| 요청 블로킹 시간 (Blocked Time) | 요청이 전송되기 전 대기한 시간             | 평균 24.77µs |
| 연결 시간 (Connecting Time)   | 서버와 연결하는 데 걸린 시간                | 평균 18.08µs |

- 서버와의 연결 지연이 거의 없으며, 요청-응답 과정이 매우 원활하게 진행되었습니다. 평균 연결 시간은 18.08µs, 요청 대기 시간은 3.83ms로 매우 짧았습니다.
- 데이터 전송 및 수신 속도도 매우 효율적이며, 평균적으로 요청은 빠르게 처리되었습니다.

#### 📌 종합 결론
- 테스트 목표인 최대 100명 동시 유저에 대해 안정적으로 성능을 발휘했습니다. 초당 평균 약 58회의 요청을 처리하면서도, 응답 시간과 성공률 모두 성능 목표를 충분히 충족했습니다.
- 95%의 요청이 6.57ms 이내로 처리되었고, 최대 응답 시간은 16.26ms로 매우 빠릅니다.
- 실패율이 0%로, 서버는 고부하 상태에서도 안정적인 성능을 보였습니다.

> 결론적으로, 서버는 초당 100개의 부하를 안정적으로 처리할 수 있으며, 빠른 응답 시간을 제공하는 것으로 확인되었습니다


---

### 4. `GET /api/v1/concert/{concertId}/schedules/{scheduleId}/seats`: 예약 가능 좌석 조회
> 다수의 유저가 동시에 좌석 정보를 조회할 때, 시스템의 응답 성능과 처리 능력을 평가하기 위한 것입니다.
> 실시간 데이터 조회에 대한 서버의 처리 능력을 테스트합니다.

#### 테스트 시나리오
- 유저 수: 초당 50명에서 100명까지 증가
- 지속 시간: 1분, 최대 peak 20초간 일정한 부하를 유지
- 선정 이유: 예약 가능 좌석 조회 API는 실시간 데이터를 다루며, 많은 유저가 동시에 좌석 정보를 조회할 때 시스템의 성능이 크게 영향을 받을 수 있습니다. 이러한 상황을 시뮬레이션하기 위해 초당 50명에서 100명까지 유저 수를 증가시키는 부하 조건을 설정하여, 시스템이 급격한 트래픽 증가에 어떻게 반응하는지 평가합니다.
- 예상 트래픽: 목표 TPS는 약 100 TPS로 설정하며, 초당 최대 100개의 좌석 조회 요청이 발생할 수 있는 상황을 평가하여 시스템의 처리 성능을 분석합니다.

#### 부하 조건
- 유저 수: 초당 50명에서 100명까지 증가
- 지속 시간: 1분, 최대 peak 20초간 일정한 부하를 유지
- 선정 이유: 예약 가능 좌석 조회 API는 실시간 데이터를 다루며, 많은 유저가 동시에 좌석 정보를 조회할 때 시스템의 성능이 크게 영향을 받을 수 있습니다. 이러한 상황을 가정하기 위해 초당 50명에서 100명까지 유저 수를 증가시키는 부하 조건을 설정하여, 시스템이 급격한 트래픽 증가에 어떻게 반응하는지 평가합니다.
- 예상 트래픽: 목표 TPS는 약 50~100 TPS로 설정하며, 초당 최대 100개의 좌석 조회 요청이 발생할 수 있는 상황을 평가하여 시스템의 처리 성능을 분석합니다.

#### K6 테스트 코드
```javascript
import http from 'k6/http';
import { check, sleep } from 'k6';

// 부하 조건 설정
export let options = {
  stages: [
    { duration: '20s', target: 50 },  // 20초 동안 50명까지 증가
    { duration: '20s', target: 100 },  // 20초 동안 100명까지 증가
    { duration: '20s', target: 50 },  // 20초 동안 50명까지 증가
  ],
  thresholds: {
    http_req_duration: ['p(95)<500'], // 95%의 요청이 500ms 미만이어야 함
    http_req_failed: ['rate<0.01'],  // 실패율은 1% 미만
  },
};

export default function () {
  let url = 'http://localhost:8080/api/v1/concerts/1/schedules/1/seats';

  // HTTP GET 요청
  let res = http.get(url);

  // 응답 검증
  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
  });

  sleep(1);
}
```

#### K6 테스트 결과 분석
```text
execution: local
  script: api-concert-seats-test.js
  output: -

scenarios: (100.00%) 1 scenario, 100 max VUs, 1m30s max duration (incl. graceful stop):
        * default: Up to 100 looping VUs for 1m0s over 3 stages (gracefulRampDown: 30s, gracefulStop: 30s)


✓ status is 200
✓ response time < 500ms

checks.........................: 100.00% 7064 out of 7064
data_received..................: 6.8 MB  111 kB/s
data_sent......................: 406 kB  6.7 kB/s
http_req_blocked...............: avg=21.29µs  min=0s     med=0s      max=5.51ms  p(90)=0s       p(95)=0s
http_req_connecting............: avg=14.93µs  min=0s     med=0s      max=2.43ms  p(90)=0s       p(95)=0s
✓ http_req_duration..............: avg=5.68ms   min=1.69ms med=4.68ms  max=51.7ms  p(90)=6.75ms   p(95)=8.04ms
 { expected_response:true }...: avg=5.68ms   min=1.69ms med=4.68ms  max=51.7ms  p(90)=6.75ms   p(95)=8.04ms
✓ http_req_failed................: 0.00%   0 out of 3532
http_req_receiving.............: avg=339.55µs min=0s     med=231.1µs max=4.23ms  p(90)=897.45µs p(95)=986.39µs
http_req_sending...............: avg=10.32µs  min=0s     med=0s      max=559.5µs p(90)=0s       p(95)=0s
http_req_tls_handshaking.......: avg=0s       min=0s     med=0s      max=0s      p(90)=0s       p(95)=0s
http_req_waiting...............: avg=5.33ms   min=1.69ms med=4.36ms  max=51.51ms p(90)=6.36ms   p(95)=7.69ms
http_reqs......................: 3532    57.917524/s
iteration_duration.............: avg=1s       min=1s     med=1s      max=1.05s   p(90)=1s       p(95)=1s
iterations.....................: 3532    57.917524/s
vus............................: 52      min=3            max=100
vus_max........................: 100     min=100          max=100
```

#### 1) 전체적인 실행 정보
- 총 실행 시간: 1분 0초 (60초)
- 최대 동시 가상 유저(VU, Virtual Users) 수: 100명
- 총 요청 횟수: 3,532회
- 초당 평균 요청 수(TPS, Throughput Per Second): 57.9회

> 테스트 목표인 초당 57.9회의 요청을 처리했습니다. 최대 동시 VU 수가 100명까지 올라갔으며, 요청 수는 테스트 계획에 맞게 분배되었습니다.

#### 2) 주요 성능 지표 (서버 응답 시간 및 요청 성공률)
| 항목                         | 설명                                    | 결과                    |
|------------------------------|-----------------------------------------|-------------------------|
| 성공한 요청 비율             | 전체 요청 중 HTTP 200 응답을 받은 비율 | 100% (3,532/3,532)      |
| 평균 응답 시간               | 요청을 보낸 후 응답을 받을 때까지 걸린 평균 시간 | 5.68ms                  |
| 최소 응답 시간               | 가장 빠르게 응답한 요청의 응답 시간    | 1.69ms                  |
| 최대 응답 시간               | 가장 오래 걸린 요청의 응답 시간       | 51.7ms                  |
| 응답 시간 (90% 이하 요청)     | 90%의 요청이 이 시간보다 빠름          | 6.75ms                  |
| 응답 시간 (95% 이하 요청)     | 95%의 요청이 이 시간보다 빠름          | 8.04ms                  |
| 최대 초당 요청 수(TPS)       | 서버가 초당 처리한 최대 요청 수        | 57.9 TPS                |

- 서버 응답 시간이 평균 5.68ms로 매우 빠르며, 95%의 요청은 8.04ms 미만으로 처리되었습니다.
- 응답 시간이 51.7ms로 가장 느린 요청이 있었지만, 여전히 설정한 성능 목표인 500ms 이하를 훨씬 만족하고 있습니다.
- 요청의 실패율이 0%로, 안정적인 서버 상태를 유지했습니다.

#### 3) 부가적인 요청 상세 정보
| 항목                         | 설명                                        | 결과        |
|------------------------------|---------------------------------------------|------------|
| 전송된 총 데이터 크기         | 서버로 보낸 총 데이터 양                    | 406 kB     |
| 받은 총 데이터 크기           | 서버에서 받은 총 데이터 양                  | 6.8 MB     |
| 요청 대기 시간 (Waiting Time) | 서버가 실제로 요청을 처리하는 데 걸린 시간   | 평균 5.33ms |
| 요청 블로킹 시간 (Blocked Time) | 요청이 전송되기 전 대기한 시간             | 평균 21.29µs |
| 연결 시간 (Connecting Time)   | 서버와 연결하는 데 걸린 시간                | 평균 14.93µs |

- 요청의 대기 시간이 평균 5.33ms로 매우 짧으며, 서버와의 연결 지연은 거의 없는 상태입니다.
- 전송된 데이터 크기와 받은 데이터 크기 간의 비율이 적당하며, 응답 데이터의 양도 효율적으로 처리되었습니다.

#### 📌 종합 결론
- 테스트 목표인 초당 57.9회의 요청을 처리하며 성능 목표를 충분히 만족했습니다.
- 평균 응답 시간은 5.68ms로 매우 빠르며, 95%의 요청이 8ms 미만으로 처리되었습니다.
- 요청 실패율은 0%로 안정적인 성능을 보였고, 최대 응답 시간이 51.7ms로 성능 목표인 500ms를 초과하지 않았습니다.

> 결론적으로, 현재 서버는 초당 100명에 대해 안정적으로 빠르게 응답할 수 있는 상태이며, 높은 부하에도 잘 견딜 수 있을 것으로 생각됩니다.


---

## 가상 장애 대응 상황 설정 및 대응
### API별 100배 부하 설정 가상 시나리오
> 각 API에 대해서 예상되는 최대 트래픽의 100배에 달하는 부하를 가정하여, 고부하 상황에서 발생 할 수 있는 병목 구간을 식별하고, 개선점을 생각해봅니다.

#### 1. `POST /api/v1/queue/tokens`
- 부하 조건: 초당 10,000명의 유저가 대기열 토큰 생성하는 상황을 가정합니다.
  - **문제점:**
    - Redis의 병목 (싱글 스레드 처리 한계, 네트워크 I/O)
    - Spring Boot 애플리케이션의 병목 (Thread Pool)
  - **개선 방향:**
    - Redis의 병목 (싱글 스레드 처리 한계, 네트워크 I/O)
      - ✅ Redis 클러스터 구성 (Sharding 적용)
        - 싱글 인스턴스 사용 시, 수평 확장 필요
        - twemproxy(nutcracker) 또는 Redis Cluster 적용하여 여러 Redis 노드로 샤딩
      - ✅ 읽기/쓰기 분리 (Master-Slave 구성 + Read Replica 활용)
        - 쓰기는 Master, 읽기는 Slave에서 처리
        - 읽기 요청이 많다면 Redis Read Replica를 추가하여 부하 분산
    - Spring Boot 애플리케이션의 병목 (Thread Pool)
      - ✅ 쓰레드 풀 최적화 (Thread Pool Optimization)
        - 적절한 쓰레드 풀 크기를 설정하여 비동기 처리를 최적화할 수 있습니다.
        - 쓰레드의 제한 시간을 두고 만약 처리가 제한된 시간을 넘어갈 시, 에러를 반환하여 서버가 다운되는 것을 방지합니다.

#### 2. `GET /api/v1/queue/status`
- 부하 조건: 초당 40,000명의 유저가 대기열 상태를 조회하는 상황을 가정합니다.
  - **문제점:**
    - Redis의 병목 (싱글 스레드 처리 한계, 네트워크 I/O)
    - Spring Boot 애플리케이션의 병목 (Thread Pool)
  - **개선 방향:**
    - Redis의 병목 (싱글 스레드 처리 한계, 네트워크 I/O)
      - ✅ Redis 클러스터 구성 (Sharding 적용)
        - 싱글 인스턴스 사용 시, 수평 확장 필요
        - twemproxy(nutcracker) 또는 Redis Cluster 적용하여 여러 Redis 노드로 샤딩
      - ✅ 읽기/쓰기 분리 (Master-Slave 구성 + Read Replica 활용)
        - 쓰기는 Master, 읽기는 Slave에서 처리
        - 읽기 요청이 많다면 Redis Read Replica를 추가하여 부하 분산
    - Polling 최적화 (Long Polling/WebSocket 고려)
      - 클라이언트가 짧은 간격으로 지속적으로 요청하는 경우, WebSocket을 사용해 상태 변화를 실시간으로 Push하는 방식 고려.
      - Long Polling을 활용해 Redis의 불필요한 조회를 줄일 수 있음.
    - Spring Boot 애플리케이션의 병목 (Thread Pool)
      - ✅ 쓰레드 풀 최적화 (Thread Pool Optimization)
        - 적절한 쓰레드 풀 크기를 설정하여 비동기 처리를 최적화할 수 있습니다.
        - 쓰레드의 제한 시간을 두고 만약 처리가 제한된 시간을 넘어갈 시, 에러를 반환하여 서버가 다운되는 것을 방지합니다.


#### 3. `GET /api/v1/concert/{concertId}/schedules`
- 부하 조건: 초당 5,000명의 유저가 동시에 특정 콘서트의 예약 가능 날짜를 조회하는 상황을 가정합니다.
  - **문제점:** 
    - 글로벌 캐시(Redis) miss로 Database로 갑작스런 부하
  - **개선 방향:**
    - 캐시 TTL 및 크기 최적화
      - ✅ 글로벌 캐시의 TTL 설정을 재검토하여 캐시 갱신 빈도를 줄이고, 캐시 크기를 확장하여 고부하 상황에서도 충분한 데이터를 캐싱할 수 있도록 합니다.
    - 로컬 캐시(Apllication Cache) 도입
      - ✅ 글로벌 캐시의 한계를 보완하기 위해 Apllication으로 캐시를 확장하여 캐시 미스로 인한 DB 부하를 줄이고, 전체적인 응답 속도를 향상시킵니다.

#### 4. `GET /api/v1/concert/{concertId}/schedules/{scheduleId}/seats`
- 부하 조건: 초당 10,000명의 유저가 특정 콘서트의 좌석 정보를 조회하는 상황을 가정합니다.
  - **문제점:**
    - 기본적으로 Database를 사용하기 때문에, 순간적으로 Database에 많은 부하가 생길 수 있습니다.
    - **개선방향**
      - ✅ Apllication에서 Database를 조회되도록 하지 않고, 무조건 Redis를 바라보게 하며 짧은 주기(1000ms 이하)로 Database에서 Redis로 정보를 주도록 하며 개선할 수 있습니다.
      - ✅ 사용되는 쿼리를 분석하여 Database 인덱스를 최적화 하는 방향을 고려해볼 수 있습니다.